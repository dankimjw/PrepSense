# PrepSense Comprehensive Test Implementation Guide

## ğŸ¯ Overview

This is a **batteries-included test bundle** for the PrepSense FastAPI + PostgreSQL + CrewAI stack. Every test is designed to be **executable and fail-fast**, preventing hallucinated "all done!" responses.

## ğŸ“ Directory Structure

```
backend_gateway/
â”œâ”€â”€ tests/                          # Main test directory
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conftest.py                 # Shared fixtures & test config
â”‚   â”œâ”€â”€ api/                        # API endpoint tests
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_chat_recommend.py  # Chat/CrewAI integration tests
â”‚   â”œâ”€â”€ domain/                     # Domain logic tests
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_crew_ai_service.py # CrewAI service logic tests
â”‚   â”œâ”€â”€ db/                         # Database tests
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_migrations.py      # Migration & schema tests
â”‚   â”œâ”€â”€ contracts/                  # OpenAPI contract tests
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ test_openapi.py         # Schemathesis fuzzing tests
â”‚   â””â”€â”€ perf/                       # Performance tests
â”‚       â”œâ”€â”€ __init__.py
â”‚       â””â”€â”€ test_performance.py     # Response time & throughput tests
â”œâ”€â”€ requirements-dev.txt            # Test dependencies
â”œâ”€â”€ pytest.ini                     # Pytest configuration
â”œâ”€â”€ locustfile.py                  # Load testing with Locust
â”œâ”€â”€ run_tests.py                   # Test runner script
â””â”€â”€ test_ingredient_matching_simple.py  # Ingredient matching tests
```

## ğŸš€ Quick Start

### 1. Install Dependencies

```bash
cd backend_gateway
pip install -r requirements-dev.txt
```

### 2. Run All Tests

```bash
# Run comprehensive test suite
python run_tests.py

# Run with load testing
python run_tests.py --load

# Run specific test categories
pytest tests/domain/ -v           # Unit tests
pytest tests/api/ -v              # Integration tests  
pytest tests/contracts/ -v        # Contract tests
pytest tests/perf/ -v -m performance  # Performance tests
```

### 3. Run Load Testing

```bash
# Basic load test
locust -H http://localhost:8000 -u 50 -r 10 --run-time 1m

# AI-intensive test
locust -H http://localhost:8000 -u 20 -r 5 --run-time 2m --locustfile locustfile.py CrewAIIntensiveUser

# Stress test
locust -H http://localhost:8000 -u 100 -r 20 --run-time 30s --locustfile locustfile.py StressTestUser
```

## ğŸ§ª Test Categories

### 1. API Tests (`tests/api/`)
- **Chat endpoint integration** with CrewAI
- **Ingredient matching consistency** between cards and details
- **Error handling** for AI service failures
- **Response format validation**
- **Dietary restrictions** handling

### 2. Domain Tests (`tests/domain/`)
- **RecipeAdvisor agent** pantry analysis
- **Ingredient name cleaning** (fixes the "lbs" bug)
- **Ingredient similarity matching**
- **Recipe scoring** and ranking logic
- **Meal type detection**

### 3. Database Tests (`tests/db/`)
- **Migration application** and rollback
- **Schema integrity** checks
- **Foreign key constraints**
- **Index performance** validation
- **Data consistency** tests

### 4. Contract Tests (`tests/contracts/`)
- **OpenAPI schema compliance** with Schemathesis
- **Request/response validation**
- **Edge case fuzzing**
- **Performance contract** verification

### 5. Performance Tests (`tests/perf/`)
- **Response time** benchmarks (< 2s normal, < 5s AI-intensive)
- **Concurrent request** handling
- **Memory usage** monitoring
- **Throughput** measurement
- **Ingredient matching** performance

## ğŸ“Š Performance Criteria

### Response Time Targets
- **Normal requests**: < 1.5s mean, < 3s P95
- **AI-intensive requests**: < 5s mean, < 10s P95
- **Database queries**: < 500ms
- **Ingredient matching**: < 100ms

### Throughput Targets
- **Normal load**: > 50 requests/second
- **Stress load**: > 20 requests/second
- **Error rate**: < 1% normal, < 5% stress

## ğŸ”§ Key Features

### CrewAI Testing
- **Mocked AI responses** for deterministic tests
- **Conversation continuity** testing
- **Complex query handling**
- **Ingredient matching accuracy**

### Ingredient Matching Bug Testing
- **Unit cleaning** (fixed "lbs" â†’ "lb" bug)
- **Modifier removal** (fixed "whole milk" â†’ "milk")
- **Consistency validation** between card counts and details
- **Edge case handling** (case sensitivity, duplicates)

### Contract Validation
- **OpenAPI compliance** with auto-generated test cases
- **Schema validation** for all endpoints
- **Error response format** consistency
- **Performance contract** enforcement

## ğŸš¨ Failure Modes

Tests are designed to **fail fast** and provide actionable feedback:

1. **Import errors** â†’ Missing dependencies or broken imports
2. **Contract violations** â†’ API doesn't match OpenAPI spec
3. **Performance degradation** â†’ Response times exceed thresholds
4. **Data inconsistency** â†’ Ingredient counts don't match
5. **AI service failures** â†’ Graceful error handling verification

## ğŸ”„ CI/CD Integration

The `.github/workflows/ci.yml` runs:
- **Backend tests** with PostgreSQL
- **Contract tests** with Schemathesis
- **Code quality** checks (Black, Ruff, Bandit)
- **Performance tests** on PRs
- **Mobile tests** (when implemented)
- **E2E tests** (when implemented)

## ğŸ“ Test Data

### Fixtures Provided
- **Sample pantry data** with expiration dates
- **Mock CrewAI responses** for deterministic testing
- **Recipe data** with ingredient lists
- **User preferences** for dietary restrictions

### Environment Variables
```bash
TESTING=true
DATABASE_URL=postgresql://test:test@localhost/test_db
OPENAI_API_KEY=test-key-123
SPOONACULAR_API_KEY=test-spoon-key
```

## ğŸ¯ How to Use with Claude

1. **Commit this test structure** to your repo
2. **Ask Claude to implement** the missing production code
3. **Run tests** to verify implementation
4. **Iterate** until all tests pass

Example prompt:
> "Here's my test structure. Implement the FastAPI chat endpoint and CrewAI service so all tests pass. The tests show exactly what the API should do."

## ğŸ† Success Metrics

When all tests pass, you'll have:
- âœ… **Working CrewAI integration** with recipe recommendations
- âœ… **Fixed ingredient matching** bug (card counts = details)
- âœ… **API contract compliance** with OpenAPI schema
- âœ… **Performance within** acceptable limits
- âœ… **Database integrity** with proper migrations
- âœ… **Error handling** that gracefully handles failures

## ğŸ” Debugging Failed Tests

### Common Issues
1. **Missing dependencies** â†’ Install from requirements-dev.txt
2. **Database connection** â†’ Check PostgreSQL container
3. **Import errors** â†’ Verify Python path in conftest.py
4. **AI service mocks** â†’ Check mock patches in tests
5. **Performance failures** â†’ Reduce load or increase thresholds

### Debug Commands
```bash
# Run with verbose output
pytest -v -s tests/

# Run specific test with pdb
pytest --pdb tests/domain/test_crew_ai_service.py::test_ingredient_matching

# Check test coverage
pytest --cov=services tests/

# Profile performance
pytest --profile tests/perf/
```

This test bundle ensures that **every feature works as expected** and **prevents regression** as the codebase evolves. The tests are the **source of truth** for how the system should behave.